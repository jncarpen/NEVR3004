{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from array import *\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from astropy.convolution import convolve, Gaussian2DKernel, Gaussian1DKernel\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# define functions\n",
    "def make_space_above(axes, topmargin=1):\n",
    "    \"\"\" increase figure size to make topmargin (in inches) space for \n",
    "        titles, without changing the axes sizes\"\"\"\n",
    "    fig = axes.flatten()[0].figure\n",
    "    s = fig.subplotpars\n",
    "    w, h = fig.get_size_inches()\n",
    "\n",
    "    figh = h - (1-s.top)*h  + topmargin\n",
    "    fig.subplots_adjust(bottom=s.bottom*h/figh, top=1-topmargin/figh)\n",
    "    fig.set_figheight(figh)\n",
    "\n",
    "    \n",
    "def angularOccupancyPlot(cellNumber):\n",
    "    \"\"\"compute tuning curve for a given neuron\"\"\"\n",
    "    \n",
    "    i = np.where(IDX == cellNumber)\n",
    "    i = i[0][0] # grab the value from np.where output\n",
    "    [Z, tetrode, loc, MI] = neuronInfo[i] # disreguard Z\n",
    "    MIround = MI.astype(np.float)\n",
    "    MIround = round(MIround,2)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, subplot_kw=dict(projection='polar'), figsize = (16,10));\n",
    "    fig.tight_layout(pad = 8.0)\n",
    "    fig.suptitle('N: {}, L: {}, MI:{}'.format(cellNumber, loc, MIround), fontsize=50, fontweight='bold');\n",
    "    plt.style.use('seaborn-white')\n",
    "    \n",
    "    plt.rcParams['savefig.facecolor'] = 'w'\n",
    "\n",
    "    axs.plot(hdEdges[i], hdOccupancy[i], color = 'crimson', linewidth =6)\n",
    "    axs.yaxis.get_major_locator().base.set_params(nbins=4) # reduce number of y-ticks\n",
    "    axs.tick_params(axis='x', labelsize=40)\n",
    "    axs.tick_params(axis='y', labelsize=40)\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def tuningCurves(cellNumber):\n",
    "    \n",
    "    \"\"\"compute tuning curve for a given neuron\"\"\"\n",
    "    \n",
    "    i = np.where(IDX == cellNumber)\n",
    "    i = i[0][0] # grab the value from np.where output\n",
    "    [Z, tetrode, loc, FR, MI] = neuronInfo[i] # disreguard Z\n",
    "    MIround = MI.astype(np.float)\n",
    "    MIround = round(MIround,2)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, subplot_kw=dict(projection='polar'), figsize = (5,6));\n",
    "    fig.tight_layout(pad = 1.0)\n",
    "    fig.suptitle('N: {}, L: {}, MI:{}'.format(cellNumber, loc, MIround), fontsize=30, fontweight='bold');\n",
    "    plt.style.use('seaborn-white')\n",
    "    \n",
    "    plt.rcParams['savefig.facecolor'] = 'w'\n",
    "\n",
    "    axs.plot(hdEdges[i], hdTuning[i], color = 'lime', linewidth = 6)\n",
    "    axs.yaxis.get_major_locator().base.set_params(nbins=4) # reduce number of y-ticks\n",
    "    axs.tick_params(axis='x', labelsize=20)\n",
    "    axs.tick_params(axis='y', labelsize=20)\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def smooth(data, sigma, **kwargs):\n",
    "    \n",
    "    # credit: Simon Ball, Moser Group (2020)\n",
    "    \n",
    "    d = data.ndim\n",
    "    \n",
    "    if  d == 2:\n",
    "        kernel = Gaussian2DKernel(x_stddev = sigma)\n",
    "    elif d == 1:\n",
    "        kernel = Gaussian1DKernel(stddev = sigma)\n",
    "    else:\n",
    "        raise NotImplementedError(\"This function currently supports smoothing\"\\\n",
    "                f\" 1D, 2D data. You have provided {d} dimensional data\")\n",
    "\n",
    "    mask_fill = 0 # Replacement value for masked values when smoothing. Use np.nan to interpolate through masked values instead of use fixed value\n",
    "\n",
    "    mask_fill = kwargs.get('mask_fill', mask_fill)\n",
    "    circular = kwargs.get(\"circular\", False)\n",
    "    if not isinstance(circular, bool):\n",
    "        raise ValueError(\"You must provide a boolean (True/False) value for\"\\\n",
    "                         f\" keyword 'circular'. You provided {circular}, which\"\\\n",
    "                         f\" is type {type(circular)}\")\n",
    "\n",
    "    working_data = data.copy()\n",
    "    if type(data) == np.ma.MaskedArray:\n",
    "        working_data[data.mask] = mask_fill\n",
    "\n",
    "    width = int(4*sigma)\n",
    "\n",
    "    if circular:\n",
    "        smoothed_data = convolve(working_data, kernel, boundary = \"wrap\")\n",
    "        # Don't bother with padding. Use the values from the other end of the \n",
    "        # array, i.e. imagine the array wrapped around a cylinder\n",
    "    elif not circular:\n",
    "        working_data = np.pad(working_data, pad_width = width, mode = 'symmetric')\n",
    "        # pad the outer boundary to depth \"width\n",
    "        # The padding values are based on reflecting at the border\n",
    "        # mode='symmetrical' results in\n",
    "        # [0, 1, 2, 3, 4] -> [1,0  ,0,1,2,3,4,  4,3]\n",
    "        # mode='reflect' results in\n",
    "        # [0, 1, 2, 3, 4] -> [2,1  ,0,1,2,3,4,  3,2]\n",
    "        # i.e. changing whether the reflection axis is outside the original data\n",
    "        # or overlaid on the outermost row\n",
    "    \n",
    "        smoothed_data = convolve(working_data, kernel, boundary = 'extend')\n",
    "        # Because of the padding, the boundary mode isn't really relevant\n",
    "        # By choosing a large width, the edge effects arising from this additional\n",
    "        # padding (boundary='extend') is minimised\n",
    "    \n",
    "        if d == 2:\n",
    "            smoothed_data = smoothed_data[width:-width, width:-width]\n",
    "        elif d == 1:\n",
    "            smoothed_data = smoothed_data[width:-width]\n",
    "        else: # This condition should never happen, due to checking above\n",
    "            raise NotImplementedError(\"This function currently supports smoothing\"\\\n",
    "                    f\" 1D, 2D data. You have provided {d} dimensional data\")\n",
    "        # We have to get rid of the padding that we previously added, and the only\n",
    "        # way to do that is slicing, which is NOT dimensional-agnostic\n",
    "        # There may be a more elegant solution than if/else, but this will do now\n",
    "\n",
    "    if type(data) == np.ma.MaskedArray:\n",
    "        smoothed_data = np.ma.masked_where(data.mask, smoothed_data)\n",
    "        smoothed_data.data[data.mask] = data.data[data.mask]\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "# load dataset\n",
    "matfile = sio.loadmat(\"C:\\\\Users\\\\17145\\\\Downloads\\\\MATLAB\\\\neural networks\\\\mouse28_interp.mat\") # load .mat file\n",
    "\n",
    "cellnames = matfile[\"cellnames\"]\n",
    "\n",
    "cell_spikes = matfile[\"cellspikes\"] # in ms\n",
    "cell_spikes = cell_spikes[0,:]\n",
    "\n",
    "tracking_times = matfile[\"trackingtimes\"] # in ms\n",
    "tracking_times = tracking_times[0,:]\n",
    "\n",
    "head_angle = matfile[\"headangle\"]\n",
    "head_angle = head_angle[0,:]\n",
    "\n",
    "position = matfile[\"position\"]\n",
    "position = position[0,:]\n",
    "\n",
    "# hack-job way of assigning tetrode locations to each cell* (PS= post-subiculum, TH= thalamus) lol \n",
    "tetLoc28 = ['PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS','PS',\n",
    "         'PS','PS','PS','PS','PS','PS','PS','PS','PS','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH','TH']\n",
    "\n",
    "tetLoc12 = ['TH'] *len(cellnames)\n",
    "\n",
    "# compute tuning curves and mutual information\n",
    "\n",
    "# define first and last timestamp\n",
    "start_time = tracking_times[1]\n",
    "stop_time = tracking_times[-1]\n",
    "\n",
    "# compute sampling frequency of video-tracking\n",
    "sp_vector, _ = stats.mode(np.diff(tracking_times)) # vector of all SPs\n",
    "Fs = np.asscalar(sp_vector) # combine this into one line \n",
    "\n",
    "# initialize empty lists to store values for each cell\n",
    "hdEdgesList = []\n",
    "hdOccupancyList = []\n",
    "hdTuningList = []\n",
    "probDensList = []\n",
    "meanFRList = []\n",
    "SPKperAngleList = []\n",
    "neuronInfoList = []\n",
    "IDXList = []\n",
    "MI_List = []\n",
    "spikesDict = {}\n",
    "\n",
    "# iterate through each cell in cell_spikes\n",
    "for iter, cell in enumerate(cell_spikes):\n",
    "    \n",
    "    # get spikes for current cell\n",
    "    spikes = cell\n",
    "    iteration = iter\n",
    "    \n",
    "#     if len(spikes)>0:\n",
    "    if np.size(spikes) >= 1000:\n",
    "    \n",
    "        # remove spike times that are outside the range of tracking times\n",
    "        boolean_spk = np.logical_and(start_time <= spikes, spikes <= stop_time)\n",
    "        spikes = spikes[boolean_spk == True]\n",
    "\n",
    "        # bin spike data [PCA]\n",
    "        timeEdges = np.linspace(start_time, stop_time, np.size(tracking_times)+1) \n",
    "        binnedSpikes, timeEdges = np.histogram(spikes, timeEdges)\n",
    "        time_ind = np.digitize(tracking_times, timeEdges);\n",
    "        \n",
    "        # smooth binnedSpikes for neuron [PCA]\n",
    "        binnedSpikes_smooth = smooth(binnedSpikes, 10)\n",
    "        \n",
    "        # compute zscore of each value in cell array relative to sample mean & std [PCA]\n",
    "        binnedSpikes_smoothNorm = stats.zscore(binnedSpikes_smooth) # dof?\n",
    "        \n",
    "\n",
    "        # bin HD data\n",
    "        HDnum_bins = 60 # 6 degree bins\n",
    "        hdEdges = np.linspace(0, 2*np.pi, HDnum_bins)\n",
    "\n",
    "        # compute angular occupancy\n",
    "        hdOccupancy, hdEdges_hist = np.histogram(head_angle, bins = HDnum_bins, range = (0, 2*np.pi)); \n",
    "        angle_ind = np.digitize(head_angle, hdEdges_hist);\n",
    "        \n",
    "        # convert hdOccupancy to seconds\n",
    "        hdOccupancy = hdOccupancy*Fs/1000\n",
    "        \n",
    "        # compute number of spikes in each time bin\n",
    "        spikesPerAngle = [];\n",
    "\n",
    "        for iBin in np.arange(1, HDnum_bins+1):\n",
    "            spikesPerAngle.append(sum(binnedSpikes[angle_ind == iBin]))\n",
    "\n",
    "        spikesPerAngle = np.asarray(spikesPerAngle)\n",
    "\n",
    "        # compute probability density (proportion of time spent at each HD angle)\n",
    "        probDens = hdOccupancy/np.sum(hdOccupancy)\n",
    "\n",
    "        # compute average firing rates across all HD angles (scalar value)\n",
    "        meanFR = np.sum(spikesPerAngle)/np.sum(hdOccupancy)\n",
    "\n",
    "        # compute tuning curve (average FR for each HD angle)\n",
    "        hdTuning = spikesPerAngle/hdOccupancy\n",
    "        \n",
    "        mutualInfo = 0\n",
    "        for i in range(HDnum_bins):\n",
    "            if hdTuning[i] != 0:\n",
    "                mutualInfo += hdTuning[i] * np.log2(hdTuning[i] / meanFR) * probDens[i]\n",
    "                \n",
    "        # divide by mean firing rate to obtain information per spike\n",
    "        mutualInfo = mutualInfo/meanFR\n",
    "        \n",
    "        neuronIN = iteration, cellnames[iteration], tetLoc28[iteration], meanFR, mutualInfo\n",
    "        neuronIndex = np.int(iteration)\n",
    "        \n",
    "        # add binnedSpikes_smoothNorm to dictionary\n",
    "        spikesDict['N{}'.format(neuronIndex)] = binnedSpikes_smoothNorm\n",
    "        \n",
    "        # append output for each cell to a series of lists\n",
    "        neuronInfoList.append(neuronIN)\n",
    "        hdEdgesList.append(hdEdges)\n",
    "        hdOccupancyList.append(hdOccupancy)\n",
    "        SPKperAngleList.append(spikesPerAngle)\n",
    "        probDensList.append(probDens)\n",
    "        meanFRList.append(meanFR)\n",
    "        hdTuningList.append(hdTuning)\n",
    "        IDXList.append(neuronIndex)\n",
    "        MI_List.append(mutualInfo)\n",
    "\n",
    "\n",
    "    # convert lists to NumPy n-dimensional arrays\n",
    "    neuronInfo = np.asarray(neuronInfoList)\n",
    "    hdEdges = np.asarray(hdEdgesList)\n",
    "    hdOccupancy = np.asarray(hdOccupancyList) # is this in seconds?\n",
    "    SPKperAngle = np.asarray(SPKperAngleList)\n",
    "    probDens = np.asarray(probDensList)\n",
    "    meanFR = np.asarray(meanFRList) \n",
    "    hdTuning = np.asarray(hdTuningList)\n",
    "    IDX = np.asarray(IDXList)\n",
    "    MI = np.asarray(MI_List)\n",
    "    \n",
    "# visualize tuning curves for all units\n",
    "# save shape of SPKperAngle in an array\n",
    "[F, G] = np.shape(SPKperAngle)\n",
    "\n",
    "# Create array of subplots\n",
    "fig, axes = plt.subplots(9,6, subplot_kw=dict(projection='polar'), figsize = (45,50))\n",
    "fig.tight_layout(h_pad= 4.0)\n",
    "fig.suptitle(\"M28: HD tuning curves (Hz)\", fontsize=50, ha='center', va='top')\n",
    "plt.style.use('seaborn-white')\n",
    "make_space_above(axes, topmargin=3.0)\n",
    "\n",
    "\n",
    "# plot all HD tuning curves\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i <= len(hdEdges)-1:\n",
    "        # plot each neuron's HD tuning curve\n",
    "        ax.plot(hdEdges[i], hdTuning[i], color = 'b', linewidth = 5)\n",
    "\n",
    "        # format subplot\n",
    "        ax.yaxis.get_major_locator().base.set_params(nbins=4) # reduce number of y-ticks\n",
    "        ax.tick_params(labelsize = 30)\n",
    "        ax.set_title('N{}, {}'.format(int(neuronInfo[i][0]), neuronInfo[i][2]), loc='left', fontsize=30, fontweight='bold')\n",
    "\n",
    "# save figure as .png file\n",
    "plt.savefig('mouse28_tuning.png')\n",
    "\n",
    "# plot occupancy & tuning curves for select units\n",
    "\n",
    "# plot angular occupancy (M12)\n",
    "angularOccupancyPlot(1)\n",
    "plt.savefig('M12_occ.png')\n",
    "\n",
    "# manual selection: units of interest\n",
    "\n",
    "# FOR MOUSE 28:\n",
    "# units with multiple peaks\n",
    "tuningCurves(8) # PS\n",
    "plt.savefig('M28_N8.png')\n",
    "tuningCurves(3) # PS\n",
    "plt.savefig('M28_N3.png')\n",
    "tuningCurves(63) # TH\n",
    "plt.savefig('M28_N63.png')\n",
    "\n",
    "# units w/ multiple peaks\n",
    "tuningCurves(25) # PS\n",
    "plt.savefig('M28_N25.png')\n",
    "tuningCurves(38) # PS\n",
    "plt.savefig('M28_N38.png')\n",
    "\n",
    "tuningCurves(60) # TH\n",
    "plt.savefig('M28_N60.png')\n",
    "tuningCurves(61) # TH\n",
    "plt.savefig('M28_N61.png')\n",
    "\n",
    "# reduce dimensionality and visualize data with PCA\n",
    "\n",
    "# convert dictionary to pandas df (I find these easier to work with)\n",
    "X = pd.DataFrame.from_dict(spikesDict)\n",
    "X.head()\n",
    "\n",
    "# for mouse 28, create dataframes for just SUB or TH data\n",
    "SUB = X.iloc[:, 0:37]\n",
    "TH = X.iloc[:,38:58]\n",
    "\n",
    "# Initialize the PCA model, here specifying/preserving 3 components [or use PCA() to allow max # of PCs]\n",
    "pca = PCA(n_components = 3, whiten = True)\n",
    "\n",
    "# Fit the PCA model, and apply it to transform the data\n",
    "out = pca.fit_transform(TH)\n",
    "principalDf = pd.DataFrame(data = out, columns = ['PC1', 'PC2', 'PC3'])\n",
    "principalDf['HA'] = angle_ind\n",
    "principalDf.head()\n",
    "\n",
    "# print explained variance ratio of first three PCs\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# visualize first two principal components\n",
    "sns.set(context = 'poster', style = 'white', font_scale = 2)\n",
    "fig, ax = plt.subplots(figsize=(17,17))\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC2\", hue='HA', linewidth = .05, s=25, data=principalDf, palette='RdYlBu')\n",
    "ax.legend_.remove()\n",
    "sns.despine()\n",
    "plt.savefig('M28TH_PCA.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
